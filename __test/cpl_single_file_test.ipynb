{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "_ROOT_PATH = \"/home/jiangpeiwen2/jiangpeiwen2/TKGT\"\n",
    "sys.path.insert(0, _ROOT_PATH)\n",
    "\n",
    "from utils import load_data, save_data,online_local_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from KGs.dataset_KGs.cpl import Plaintiff_claim_attributes, cpl_keyword\n",
    "from date_capture import CplDocumentRatioTextCapture, CplDocumentMoneyTextCapture, CplDocumentDateTextCapture\n",
    "from test_utils import load_mat, compare, find_context_from_prompt, cpl_post_process_simple, index_after_shuffle, eval_simple\n",
    "from Hybird_RAG.retriever.retrieve_hybrid import CPL_Hybrid_Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from modelscope.models import Model\n",
    "from modelscope.pipelines import pipeline\n",
    "# Version less than 1.1 please use TextRankingPreprocessor\n",
    "from modelscope.preprocessors import TextRankingTransformersPreprocessor\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-11-06 23:04:32,175 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:32,422 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:32,423 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:32,425 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:33,773 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/utils/checkpoint.py:550: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt_file, map_location='cpu')\n",
      "2024-11-06 23:04:34,073 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:04:34,074 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:04:36,023 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:36,275 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:36,276 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:36,278 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:37,572 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:04:37,873 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:04:37,873 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:04:39,977 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:40,219 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:40,221 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:40,223 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:41,677 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:04:41,966 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:04:41,967 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:04:43,828 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:44,084 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:44,085 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:44,087 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:45,435 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:04:45,721 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:04:45,722 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:04:47,969 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:48,218 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:48,219 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:48,222 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:49,626 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:04:49,915 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:04:49,917 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:04:53,112 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:53,341 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:53,342 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:53,344 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:54,692 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:04:54,984 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:04:54,985 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:04:58,300 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:04:58,545 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:58,546 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:04:58,548 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:04:59,973 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:00,246 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:00,246 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:03,420 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:03,668 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:03,669 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:03,671 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:05,236 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:05,507 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:05,508 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:07,546 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:07,899 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:07,900 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:07,902 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:09,224 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:09,518 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:09,519 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:12,255 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:12,526 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:12,527 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:12,529 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:14,040 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:14,308 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:14,308 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:17,830 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:18,202 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:18,203 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:18,204 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:19,699 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:20,030 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:20,032 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:22,064 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:22,475 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:22,477 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:22,480 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:23,931 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:24,441 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:24,442 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:27,422 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:27,672 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:27,673 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:27,676 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:29,336 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:29,649 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:29,650 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:31,896 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:32,144 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:32,146 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:32,153 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:33,912 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:34,276 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:34,286 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:36,794 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:37,140 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:37,141 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:37,143 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:38,830 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 23:05:39,528 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 23:05:39,530 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "2024-11-06 23:05:42,324 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 23:05:42,571 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:42,572 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 23:05:42,574 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 23:05:44,170 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(gpu)\n\u001b[1;32m      8\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m HuggingFaceEmbedding(\n\u001b[1;32m      9\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jiangpeiwen2/jiangpeiwen2/LlamaIndex/model/sentence-transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m rerank_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_ranking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdamo/nlp_rom_passage-ranking_chinese-base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv1.1.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgpu\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#model_dict.append( embed_model )\u001b[39;00m\n\u001b[1;32m     13\u001b[0m temp\u001b[38;5;241m.\u001b[39mappend( (embed_model, rerank_pipeline) )\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/pipelines/builder.py:169\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, preprocessor, config_file, pipeline_name, framework, device, model_revision, ignore_file_pattern, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mpreprocessor \u001b[38;5;241m=\u001b[39m preprocessor\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/pipelines/builder.py:65\u001b[0m, in \u001b[0;36mbuild_pipeline\u001b[0;34m(cfg, task_name, default_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_pipeline\u001b[39m(cfg: ConfigDict,\n\u001b[1;32m     55\u001b[0m                    task_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m                    default_args: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" build pipeline given model config dict.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        default_args (dict, optional): Default initialization arguments.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPIPELINES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/utils/registry.py:212\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, group_key, default_args)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj_cls\u001b[38;5;241m.\u001b[39m_instantiate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Normal TypeError does not print class name.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/pipelines/nlp/text_ranking_pipeline.py:41\u001b[0m, in \u001b[0;36mTextRankingPipeline.__init__\u001b[0;34m(self, model, preprocessor, config_file, device, auto_collate, sequence_length, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     24\u001b[0m              model: Union[Model, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     25\u001b[0m              preprocessor: Optional[Preprocessor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m              sequence_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     30\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use `model` and `preprocessor` to create a nlp word segment pipeline for prediction.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m            Extra kwargs passed into the preprocessor's constructor.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauto_collate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_collate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompile_options\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, Model), \\\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease check whether model config exists in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mModelFile\u001b[38;5;241m.\u001b[39mCONFIGURATION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/pipelines/base.py:100\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, config_file, model, preprocessor, device, auto_collate, device_map, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_name \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, List):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_single_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/pipelines/base.py:53\u001b[0m, in \u001b[0;36mPipeline.initiate_single_model\u001b[0;34m(self, model, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitiate model from location \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# expecting model has been prefetched to local cache beforehand\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_prefetched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43minvoked_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mInvoke\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPELINE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m is_model(model) \u001b[38;5;28;01melse\u001b[39;00m model\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/models/base/base_model.py:183\u001b[0m, in \u001b[0;36mModel.from_pretrained\u001b[0;34m(cls, model_name_or_path, revision, cfg_dict, device, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_backbone(model_cfg)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# dynamically add pipeline info to model for pipeline inference\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cfg, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/models/builder.py:35\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg, task_name, default_args)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" build model given model config dict\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    default_args (dict, optional): Default initialization arguments.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Handle subtask with a backbone model that hasn't been registered\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# All the subtask with a parent task should have a task model, otherwise it is not a\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# valid subtask\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     parent_task, task_model_type \u001b[38;5;241m=\u001b[39m get_task_by_subtask_name(task_name)\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/utils/registry.py:210\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, group_key, default_args)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj_cls, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_instantiate\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/models/nlp/task_models/task_model.py:687\u001b[0m, in \u001b[0;36mEncoderModel._instantiate\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_dir\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    686\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 687\u001b[0m model_load_handler \u001b[38;5;241m=\u001b[39m \u001b[43mload_task_model_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_local_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_load_handler[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/utils/checkpoint.py:550\u001b[0m, in \u001b[0;36mload_task_model_checkpoint\u001b[0;34m(model_to_load, model_local_dir, default_dtype, load_state_fn, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# TODO Sharded ckpt\u001b[39;00m\n\u001b[1;32m    549\u001b[0m ckpt_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_local_dir, ModelFile\u001b[38;5;241m.\u001b[39mTORCH_MODEL_BIN_FILE)\n\u001b[0;32m--> 550\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(default_dtype)\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/torch/serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/torch/serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/torch/serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/torch/serialization.py:1772\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1769\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset : storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m     storage \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1772\u001b[0m         \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m         \u001b[38;5;241m.\u001b[39m_typed_storage()\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1775\u001b[0m     )\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_dict = []\n",
    "for gpu in range( 8 ):\n",
    "    #for time_ in range(7):\n",
    "    temp = []\n",
    "    for i in range(7):\n",
    "        # os.environ[\"CUDA_VISIBLE_DEVICES\"]  = str(gpu)\n",
    "        torch.cuda.set_device(gpu)\n",
    "        embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"/home/jiangpeiwen2/jiangpeiwen2/LlamaIndex/model/sentence-transformer\"\n",
    "        )\n",
    "        rerank_pipeline = pipeline(task=Tasks.text_ranking, model='damo/nlp_rom_passage-ranking_chinese-base', model_revision='v1.1.0', device=f\"cuda:{gpu}\")\n",
    "        #model_dict.append( embed_model )\n",
    "        temp.append( (embed_model, rerank_pipeline) )\n",
    "    model_dict.append( temp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scores': [0.4277496635913849]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_inputs = {\n",
    "            'source_sentence': [\"你好\"],\n",
    "            'sentences_to_compare': [\"你好\"]\n",
    "        }\n",
    "model_dict[0][1](input=auto_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label有2364个，提示词有1928个，一样的有1231个\n"
     ]
    }
   ],
   "source": [
    "_MODE = \"debug\"\n",
    "\n",
    "if _MODE == \"test\":\n",
    "    predict_lists, prompt_lists, label_lists, texts, core_ruled_text, entity_lists, context_lists = load_mat( _MODE )\n",
    "    \n",
    "elif _MODE == \"train\":\n",
    "    core_ruled_text, texts, label_lists, entity_lists = load_mat( _MODE )\n",
    "elif _MODE == \"debug\":\n",
    "    pair = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/evaluation/eval_results/history/cpl_data_cell_all_eval_pair_list.pickle\", \"pickle\")\n",
    "    label_lists, predict_lists = pair[0], pair[1]   # 1456个测试样本，每个样本的prompt为0或12或24\n",
    "    prompt_lists = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_prompt_list.pickle\", \"pickle\")\n",
    "    texts = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/data/cpl/test.text\" , \"text\")\n",
    "    core_ruled_text = CPL_Hybrid_Retriever.cpl_batch_process( \"test\")\n",
    "    # 比较预测结果\n",
    "    \n",
    "    def compare_predict( predict_lists, label_lists ):\n",
    "        prompt_count = 0\n",
    "        label_count = 0\n",
    "\n",
    "        same_count = []\n",
    "        label_not = []\n",
    "        same_count_pre = []\n",
    "        for i in range( len(predict_lists)):\n",
    "            prompt_count += len( predict_lists[i] )\n",
    "            label_count += len( label_lists[i] )\n",
    "            for item in label_lists[i]:\n",
    "                # 两者一样\n",
    "                if item in predict_lists[i]:\n",
    "                    same_count.append( item )\n",
    "                else:   \n",
    "                    label_not.append( item )\n",
    "            for item in predict_lists[i]:\n",
    "                # 如果预测中的不在一样的里面\n",
    "                if item not in same_count:\n",
    "                    same_count_pre.append( item )\n",
    "        print(f\"label有{label_count}个，提示词有{prompt_count}个，一样的有{len(same_count)}个\")\n",
    "        return same_count, label_not, same_count_pre\n",
    "    same_count, label_not, same_count_pre = compare_predict( predict_lists, label_lists )\n",
    "    \"\"\"\"\"\"\n",
    "elif _MODE == \"post_process\":\n",
    "    predict_lists = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_predict_list.pickle\", \"pickle\")\n",
    "    column_lists = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_column_list.pickle\", \"pickle\")\n",
    "    label_lists = load_data( \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_label_list.pickle\", \"pickle\")\n",
    "    new_predicts_list = []\n",
    "    new_labels_list = []\n",
    "    for i in range(len(predict_lists)):\n",
    "        temp = set()\n",
    "        for j in range(len( predict_lists[i])):\n",
    "            temp.add( (column_lists[i][j][0], column_lists[i][j][1], predict_lists[i][j]))\n",
    "        ret_label_set, ret_predict_set = cpl_post_process_simple( temp, label_lists[i])\n",
    "        new_predicts_list.append( ret_predict_set )\n",
    "        new_labels_list.append( ret_label_set )\n",
    "    save_data( (new_labels_list, new_predicts_list),\"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/evaluation/eval_results/cpl_data_cell_all_eval_pair_list.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款金额50万元整', '本院认为，原告贾瑞起与被告李安新之间最初签订《合作经营协议书》，原告所付款项50万元虽名为投资款，但根据该协议书约定，原告有权收回所付款项，并确保获得相对明确的收益，且不参与公司的任何管理，不承担任何亏损，双方的行为和资金往来更符合借贷的特征', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 需返还利息率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['其中244,000元被告在到期日之前用其他费用进行了冲抵，双方确认欠款256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2013年5月31日，原告向被告李安新付款50万元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2013年5月31日，原告向被告李安新付款50万元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 需返还违约金数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。不要和利息率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款金额50万元整', '被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['2013年5月31日，原告向被告李安新付款50万元', '2016年4月13日，经结算，被告李安新出具声明一份，内容为：“因欠贾瑞起人民币贰拾伍万陆仟元整（￥256,000.00），本人自愿将宝马3xxxl白色车辆抵押给贾瑞起，本人在30天内将欠贾瑞起￥256,000.00元还清，贾瑞起将车辆归还给我，如30天未归还，车辆由贾瑞起处置，车架号：LXXXXXXXXXXXXXXX6', '2015年12月3日，原告作为出借人与作为借款人的被告李安新签订了《借款协议》一份，约定：为了明确责任，恪守信用，在双方自愿、协商情况下特签订本合同以资共同信守', '借款期限自2015年12月3日起至2016年5月31日止']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的还款日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和实际归还的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 初始约定的还款日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和实际归还的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的利率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的逾期利率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。很少见，不要和正常利率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的违约金数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。很少见，不要和利率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['特别是，被告李安新嗣后与原告签订《借款协议》并出具借据，将原告所付50万元款项进一步明确为借款，故双方形成的是借贷关系', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '借款金额50万元整', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款', '事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2015年12月3日，原告作为出借人与作为借款人的被告李安新签订了《借款协议》一份，约定：为了明确责任，恪守信用，在双方自愿、协商情况下特签订本合同以资共同信守', '借款期限自2015年12月3日起至2016年5月31日止']\\n问题：法院 (上海市闵行区人民法院) 判定 借款实际交付时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是实际上原告把钱给被告的日期，不要和其他的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 借款实际交付时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是实际上原告把钱给被告的日期，不要和其他的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '2016年4月13日，经结算，被告李安新出具声明一份，内容为：“因欠贾瑞起人民币贰拾伍万陆仟元整（￥256,000.00），本人自愿将宝马3xxxl白色车辆抵押给贾瑞起，本人在30天内将欠贾瑞起￥256,000.00元还清，贾瑞起将车辆归还给我，如30天未归还，车辆由贾瑞起处置，车架号：LXXXXXXXXXXXXXXX6']\\n问题：法院 (上海市闵行区人民法院) 判定 已还款时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是被告还钱给原告的日期，不要和其他日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 已还款时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是被告还钱给原告的日期，不要和其他日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '第一年甲方归还乙方10万元，第二年甲方归还乙方20万元，第三年甲方归还乙方2万元，第三、四、五年甲方按规定每年支付给乙方15万元']\\n问题：法院 (上海市闵行区人民法院) 判定 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('上海市闵行区人民法院', '借款实际交付时间1', '2013-05-31'),\n",
       " ('上海市闵行区人民法院', '已还款金额1（元）', '100000'),\n",
       " ('贾瑞起', '借款实际交付时间1', '2013-05-31'),\n",
       " ('贾瑞起', '借款实际交付金额1（元）', '500000'),\n",
       " ('贾瑞起', '初始约定的借款金额（元）', '500000'),\n",
       " ('贾瑞起', '需返回本金总额（元）', '256000')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('上海市闵行区人民法院', '借款实际交付时间1', '2013-05-31'),\n",
       " ('上海市闵行区人民法院', '借款实际交付金额1（元）', '500000'),\n",
       " ('上海市闵行区人民法院', '初始约定的借款金额（元）', '500000'),\n",
       " ('上海市闵行区人民法院', '初始约定的还款日期', '2015-12-03'),\n",
       " ('上海市闵行区人民法院', '已还款金额1（元）', '244000'),\n",
       " ('上海市闵行区人民法院', '需返回本金总额（元）', '256000'),\n",
       " ('贾瑞起', '借款实际交付时间1', '2013-05-31'),\n",
       " ('贾瑞起', '借款实际交付金额1（元）', '500000'),\n",
       " ('贾瑞起', '初始约定的借款金额（元）', '500000'),\n",
       " ('贾瑞起', '已还款金额1（元）', '244000'),\n",
       " ('贾瑞起', '需返回本金总额（元）', '256000')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款金额50万元整', '本院认为，原告贾瑞起与被告李安新之间最初签订《合作经营协议书》，原告所付款项50万元虽名为投资款，但根据该协议书约定，原告有权收回所付款项，并确保获得相对明确的收益，且不参与公司的任何管理，不承担任何亏损，双方的行为和资金往来更符合借贷的特征', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 需返还利息率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['其中244,000元被告在到期日之前用其他费用进行了冲抵，双方确认欠款256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2013年5月31日，原告向被告李安新付款50万元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2013年5月31日，原告向被告李安新付款50万元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 需返还违约金数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。不要和利息率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款金额50万元整', '被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['2013年5月31日，原告向被告李安新付款50万元', '2016年4月13日，经结算，被告李安新出具声明一份，内容为：“因欠贾瑞起人民币贰拾伍万陆仟元整（￥256,000.00），本人自愿将宝马3xxxl白色车辆抵押给贾瑞起，本人在30天内将欠贾瑞起￥256,000.00元还清，贾瑞起将车辆归还给我，如30天未归还，车辆由贾瑞起处置，车架号：LXXXXXXXXXXXXXXX6', '2015年12月3日，原告作为出借人与作为借款人的被告李安新签订了《借款协议》一份，约定：为了明确责任，恪守信用，在双方自愿、协商情况下特签订本合同以资共同信守', '借款期限自2015年12月3日起至2016年5月31日止']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的还款日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和实际归还的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 初始约定的还款日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和实际归还的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的利率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的逾期利率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。很少见，不要和正常利率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的违约金数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。很少见，不要和利率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['特别是，被告李安新嗣后与原告签订《借款协议》并出具借据，将原告所付50万元款项进一步明确为借款，故双方形成的是借贷关系', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '借款金额50万元整', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款', '事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2015年12月3日，原告作为出借人与作为借款人的被告李安新签订了《借款协议》一份，约定：为了明确责任，恪守信用，在双方自愿、协商情况下特签订本合同以资共同信守', '借款期限自2015年12月3日起至2016年5月31日止']\\n问题：法院 (上海市闵行区人民法院) 判定 借款实际交付时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是实际上原告把钱给被告的日期，不要和其他的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 借款实际交付时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是实际上原告把钱给被告的日期，不要和其他的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '2016年4月13日，经结算，被告李安新出具声明一份，内容为：“因欠贾瑞起人民币贰拾伍万陆仟元整（￥256,000.00），本人自愿将宝马3xxxl白色车辆抵押给贾瑞起，本人在30天内将欠贾瑞起￥256,000.00元还清，贾瑞起将车辆归还给我，如30天未归还，车辆由贾瑞起处置，车架号：LXXXXXXXXXXXXXXX6']\\n问题：法院 (上海市闵行区人民法院) 判定 已还款时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是被告还钱给原告的日期，不要和其他日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 已还款时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是被告还钱给原告的日期，不要和其他日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '第一年甲方归还乙方10万元，第二年甲方归还乙方20万元，第三年甲方归还乙方2万元，第三、四、五年甲方按规定每年支付给乙方15万元']\\n问题：法院 (上海市闵行区人民法院) 判定 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取提示词和label：return ret_list, new_label, first_column, contexts\n",
    "prompt_temp_instruction = \"\"\"\n",
    "你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\n",
    "（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\n",
    "（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\n",
    "\"\"\"\n",
    "prompt_temp_input = \"\"\"\n",
    "相关上下文：{CONTEXT}\n",
    "问题：{ROLE} {PREDICATE} {ATTRIBUTE}？\n",
    "注意：{ATTENTION}\n",
    "答案：\n",
    "\"\"\"\n",
    "\n",
    "PREDICATEs = {\n",
    "    \"法院\": \"判定\",\n",
    "    \"原告\": \"诉称\",\n",
    "    \"被告\": \"辩称\",\n",
    "}\n",
    "\n",
    "def get_ruled_context_( predicate, entity, attr, hybrid_retriever):\n",
    "    # 获取当前角色类型和名称\n",
    "    entity_name = None\n",
    "    entity_type = None\n",
    "    for word in [\"法院\", \"原告\", \"被告\"]:\n",
    "        if word in entity:\n",
    "            entity_type = word\n",
    "            entity_name = entity.split(\" \")[1].replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "            break\n",
    "    # 获取ruled_text中对应的部分\n",
    "    query = entity_type + predicate + attr + \"？\"\n",
    "    context = hybrid_retriever.hybrid_retrieve( query, entity, attr)\n",
    "    if entity_type == \"被告\":\n",
    "        filter_context = []\n",
    "        for line in context:\n",
    "            if entity_name in line:\n",
    "                filter_context.append( line )\n",
    "        context = filter_context\n",
    "    return context, cpl_keyword[attr][\"warning\"]\n",
    "\n",
    "# 从label集合中获取答案，服务于ft\n",
    "def get_ans_from_label( label, entity, attr ):\n",
    "    entity_name = None\n",
    "    entity_type = None\n",
    "    for word in [\"法院\", \"原告\", \"被告\"]:\n",
    "        if word in entity:\n",
    "            entity_type = word\n",
    "            entity_name = entity.split(\" \")[1].replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "            break\n",
    "    if entity_name != None:\n",
    "        for item in label:\n",
    "            if item[0]==entity_name and item[1]==attr:\n",
    "                return item[2]\n",
    "    return \"<NOT FOUND>\"\n",
    "\n",
    "def get_ready_context( contexts_ready, attr, entity_name ):\n",
    "    attr_clean = attr if \"1\" not in attr else attr.replace(\"1\", \"\")\n",
    "    flag = 0\n",
    "    for line in contexts_ready:\n",
    "        clear_line = line.split(\"\\n\\n问题：\")[1].split(\"\\n主体角色\")[0]\n",
    "        if attr_clean in line and entity_name in line:\n",
    "            flag = 1\n",
    "            context = line\n",
    "            break\n",
    "    if flag == 0:\n",
    "        context = []\n",
    "    return context, cpl_keyword[attr][\"warning\"]\n",
    "\n",
    "\n",
    "# 对单个文档，更新prompt和对应的label，返回可以直接评估的集合格式\n",
    "def get_prompts_labels( entity_list, index, Plaintiff_claim_attributes, label, core_ruled_text, _entity_type=None, contexts_ready = None):\n",
    "    ret_list = []\n",
    "    first_column = []\n",
    "    contexts = []\n",
    "\n",
    "    # 处理标签\n",
    "    new_label = set()\n",
    "    for item in label:\n",
    "        for ent in entity_list:\n",
    "            try:\n",
    "                if item[0] in ent:\n",
    "                    item_type = ent\n",
    "                    break\n",
    "            except:\n",
    "                raise Exception( f\"{item}, {ent}\")\n",
    "        if _entity_type == None or _entity_type in item_type:\n",
    "            new_label.add( item )\n",
    "\n",
    "    attr_list = list(Plaintiff_claim_attributes.keys())\n",
    "    # 遍历所有属性\n",
    "    for i in tqdm(range(len(attr_list)), desc=f\"正在处理第{index}个文档的属性\"):\n",
    "        attr = attr_list[i]\n",
    "        if attr != \"姓名名称\":\n",
    "            if \"（元）\" in attr:\n",
    "                attr_typ = \"money\"\n",
    "            elif \"日期\" in attr or \"时间\" in attr:\n",
    "                attr_typ = \"date\"\n",
    "            elif \"（百分比或元）\" in attr:\n",
    "                attr_typ = \"ratio\"\n",
    "            \n",
    "\n",
    "            for j, entity in enumerate(entity_list):\n",
    "                # 遍历形式['法院 (上海市闵行区人民法院)', '出借人（原告） (陈达奋)', '借款人（被告） (陈银森)', '借款人（被告） (郑丽珍)']\n",
    "                if _entity_type==None or _entity_type in entity:\n",
    "                    # entity_type为两个字\n",
    "                    for word in [\"法院\", \"原告\", \"被告\"]:\n",
    "                        if word in entity:\n",
    "                            entity_type = word\n",
    "                            entity_name = entity.split(\" \")[1].replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "                            break\n",
    "                    if contexts_ready == None:\n",
    "                        hybrid_retriever = CPL_Hybrid_Retriever( core_ruled_text[index], attr_typ, entity_type )\n",
    "                    if contexts_ready != None:\n",
    "                        context, attention = get_ready_context( contexts_ready, attr, entity_name )\n",
    "                    else:\n",
    "                        context, attention = get_ruled_context_( PREDICATEs[entity_type], entity, attr, hybrid_retriever)\n",
    "                    # context, attention = get_ruled_context(  entity, attr, label)\n",
    "                    if len(context)!=0:\n",
    "                        contexts.append( context )\n",
    "                        first_column.append( [entity_name, attr])\n",
    "                        if \"1\" in attr:\n",
    "                            _attr = attr.replace(\"1\", \"\")\n",
    "                        else:\n",
    "                            _attr = attr\n",
    "                        if _MODE == \"test\":\n",
    "                            prompt = prompt_temp_instruction + prompt_temp_input.format( ROLE = entity, PREDICATE=PREDICATEs[entity_type], \n",
    "                                                                                        ATTRIBUTE=_attr, CONTEXT=context, ATTENTION=attention)\n",
    "                        else:\n",
    "                            prompt = {\n",
    "                                \"instruction\" : prompt_temp_instruction,\n",
    "                                \"input\" : prompt_temp_input.format( ROLE = entity, PREDICATE=PREDICATEs[entity_type], ATTRIBUTE=_attr, CONTEXT=context, ATTENTION=attention ),\n",
    "                                \"output\": get_ans_from_label( label, entity, attr )     # 从label获取答案\n",
    "                            }\n",
    "                        ret_list.append( prompt )\n",
    "    if contexts_ready!=None:\n",
    "        contexts = contexts_ready\n",
    "    return ret_list, new_label, first_column, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "正在处理第0个文档的属性:   0%|          | 0/19 [00:00<?, ?it/s]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:11,329 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:11,587 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:11,588 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:11,590 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:12,768 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/modelscope/utils/checkpoint.py:550: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt_file, map_location='cpu')\n",
      "2024-11-06 20:24:13,022 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:13,023 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:13,851 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:14,124 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:14,125 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:14,127 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:15,253 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:15,508 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:15,509 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:16,405 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:16,664 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:16,665 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:16,667 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:17,802 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:18,083 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:18,084 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:18,901 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:19,154 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:19,155 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:19,157 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:20,376 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:20,655 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:20,657 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  11%|█         | 2/19 [00:10<01:28,  5.19s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:21,612 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:21,871 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:21,872 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:21,874 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:23,015 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:23,266 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:23,267 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:24,071 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:24,305 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:24,306 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:24,308 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:25,486 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:25,772 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:25,773 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:26,584 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:26,834 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:26,835 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:26,837 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:27,986 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:28,238 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:28,239 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:29,148 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:29,491 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:29,492 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:29,494 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:30,774 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:31,046 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:31,047 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  16%|█▌        | 3/19 [00:20<01:57,  7.35s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:31,982 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:32,228 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:32,229 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:32,232 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:33,375 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:33,627 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:33,627 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/retriever/retriever_bm25.py:58: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_top_k_values = top_k_values / max_abs_val\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:34,430 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:34,788 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:34,789 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:34,791 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:36,016 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:36,297 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:36,298 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/bm25s/__init__.py:300: RuntimeWarning: Mean of empty slice.\n",
      "  avg_doc_len = np.array([len(doc_ids) for doc_ids in corpus_token_ids]).mean()\n",
      "/home/jiangpeiwen2/jiangpeiwen2/miniconda3/envs/llamaindex/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "2024-11-06 20:24:37,105 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:37,373 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:37,373 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:37,376 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:38,525 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:38,775 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:38,775 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:39,706 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:39,964 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:39,965 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:39,967 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:41,218 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:41,499 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:41,500 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  21%|██        | 4/19 [00:31<02:07,  8.47s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:42,245 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:42,588 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:42,589 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:42,592 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:43,748 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:44,023 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:44,024 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:44,845 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:45,099 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:45,100 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:45,101 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:46,312 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:46,548 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:46,549 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:47,443 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:47,703 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:47,704 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:47,706 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:48,862 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:49,093 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:49,094 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:49,848 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:50,178 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:50,179 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:50,182 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:51,412 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:51,703 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:51,704 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  26%|██▋       | 5/19 [00:41<02:07,  9.07s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:52,401 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:52,770 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:52,771 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:52,773 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:53,996 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:54,274 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:54,275 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:55,084 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:55,343 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:55,344 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:55,347 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:56,503 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:56,678 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:56,679 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:57,380 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:24:57,629 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:57,630 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:24:57,632 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:24:58,803 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:24:59,083 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:24:59,084 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:24:59,777 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:00,063 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:00,064 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:00,066 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:01,233 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:01,502 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:01,503 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  32%|███▏      | 6/19 [00:51<02:01,  9.31s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:02,244 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:02,523 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:02,524 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:02,526 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:03,676 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:03,933 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:03,934 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:04,747 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:04,989 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:04,990 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:04,993 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:06,184 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:06,406 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:06,407 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:07,288 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:07,665 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:07,666 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:07,668 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:08,799 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:08,978 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:08,978 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:09,735 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:09,992 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:09,993 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:09,995 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:11,131 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:11,295 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:11,295 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  37%|███▋      | 7/19 [01:00<01:53,  9.49s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:12,179 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:12,424 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:12,424 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:12,426 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:13,554 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:13,740 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:13,741 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:14,672 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:14,957 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:14,958 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:14,960 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:16,135 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:16,336 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:16,337 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:17,205 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:17,574 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:17,575 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:17,577 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:18,711 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:18,888 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:18,888 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:19,560 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:19,822 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:19,823 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:19,826 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:20,985 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:21,274 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:21,275 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  42%|████▏     | 8/19 [01:10<01:45,  9.62s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:21,999 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:22,256 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:22,257 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:22,259 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:23,438 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:23,706 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:23,707 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:24,556 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:24,920 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:24,921 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:24,923 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:26,077 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:26,297 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:26,298 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:27,191 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:27,537 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:27,538 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:27,541 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:28,686 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:28,850 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:28,851 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:29,514 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:29,875 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:29,876 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:29,878 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:31,033 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:31,313 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:31,314 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  47%|████▋     | 9/19 [01:20<01:37,  9.75s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:32,012 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:32,359 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:32,360 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:32,362 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:33,516 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:33,781 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:33,782 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:34,659 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:35,002 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:35,003 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:35,005 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:36,192 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:36,423 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:36,424 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:37,084 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:37,334 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:37,335 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:37,337 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:38,523 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:38,807 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:38,808 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:39,453 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:39,786 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:39,787 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:39,790 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:40,957 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:41,211 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:41,211 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  53%|█████▎    | 10/19 [01:30<01:28,  9.79s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:41,907 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:42,171 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:42,172 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:42,175 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:43,308 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:43,556 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:43,557 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:44,455 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:44,846 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:44,847 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:44,849 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:45,995 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:46,177 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:46,178 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:47,117 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:47,375 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:47,376 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:47,379 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:48,506 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:48,679 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:48,680 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:49,473 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:49,743 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:49,744 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:49,747 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:50,892 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:51,048 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:51,049 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  58%|█████▊    | 11/19 [01:40<01:18,  9.84s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:51,839 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:52,225 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:52,226 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:52,229 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:53,368 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:53,514 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:53,515 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:54,319 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:54,562 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:54,563 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:54,565 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:55,700 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:55,839 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:55,840 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:56,691 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:56,943 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:56,944 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:56,946 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:58,085 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:25:58,227 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:25:58,488 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:25:59,132 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:25:59,372 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:25:59,373 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:25:59,375 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:00,531 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:00,725 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:00,727 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  63%|██████▎   | 12/19 [01:50<01:08,  9.75s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:01,377 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:01,757 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:01,758 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:01,760 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:02,897 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:03,073 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:03,074 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:03,945 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:04,196 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:04,197 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:04,199 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:05,357 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:05,514 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:05,515 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:06,175 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:06,430 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:06,431 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:06,433 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:07,621 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:07,848 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:07,849 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:08,631 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:08,886 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:08,887 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:08,890 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:10,076 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:10,366 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:10,367 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  68%|██████▊   | 13/19 [01:59<00:58,  9.72s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:11,166 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:11,437 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:11,438 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:11,440 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:12,594 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:12,767 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:12,768 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:13,652 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:13,900 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:13,902 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:13,903 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:15,047 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:15,211 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:15,212 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:15,962 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:16,241 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:16,242 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:16,244 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:17,378 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:17,581 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:17,582 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:18,272 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:18,514 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:18,515 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:18,517 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:19,663 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:19,868 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:19,869 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  74%|███████▎  | 14/19 [02:09<00:48,  9.66s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:20,577 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:20,933 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:20,934 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:20,937 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:22,089 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:22,298 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:22,298 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:23,199 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:23,568 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:23,569 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:23,571 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:24,798 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:25,019 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:25,020 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:25,713 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:25,988 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:25,989 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:25,991 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:27,135 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:27,381 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:27,382 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:28,047 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:28,403 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:28,404 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:28,407 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:29,541 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:29,773 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:29,774 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  79%|███████▉  | 15/19 [02:19<00:38,  9.73s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:30,541 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:30,795 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:30,797 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:30,799 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:31,937 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:32,150 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:32,152 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:33,068 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:33,416 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:33,417 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:33,419 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:34,548 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:34,693 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:34,693 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:35,505 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:35,847 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:35,849 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:35,851 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:36,994 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:37,143 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:37,143 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:38,043 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:38,407 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:38,408 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:38,410 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:39,550 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:39,694 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:39,695 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  84%|████████▍ | 16/19 [02:29<00:29,  9.82s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:40,597 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:40,838 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:40,840 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:40,841 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:42,002 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:42,201 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:42,201 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:42,995 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:43,395 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:43,396 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:43,398 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:44,537 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:44,684 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:44,684 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:45,553 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:45,900 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:45,901 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:45,903 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:47,040 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:47,194 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:47,195 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:47,847 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:48,095 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:48,096 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:48,098 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:49,235 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:49,439 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:49,439 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  89%|████████▉ | 17/19 [02:39<00:19,  9.77s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:50,245 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:50,518 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:50,520 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:50,522 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:51,652 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:51,870 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:51,871 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:52,748 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:52,997 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:52,998 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:53,000 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:54,135 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:54,286 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:54,287 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:55,203 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:55,454 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:55,456 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:55,457 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:56,639 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:56,816 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:56,817 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:57,463 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:26:57,832 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:57,833 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:26:57,836 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:26:58,977 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:26:59,236 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:26:59,237 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性:  95%|█████████▍| 18/19 [02:48<00:09,  9.78s/it]The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:26:59,945 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:27:00,835 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:00,836 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:27:00,838 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:01,984 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:27:02,199 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:27:02,200 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:27:03,017 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:27:03,389 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:03,390 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:27:03,392 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:04,523 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:27:04,671 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:27:04,672 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:27:05,559 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:27:05,796 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:05,796 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:27:05,797 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:06,935 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:27:07,083 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:27:07,084 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "The tokenizer parameter is deprecated and will be removed in a future release. Use a stemmer from PyStemmer instead.\n",
      "2024-11-06 20:27:07,988 - modelscope - INFO - Use user-specified model revision: v1.1.0\n",
      "2024-11-06 20:27:08,243 - modelscope - INFO - initiate model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:08,244 - modelscope - INFO - initiate model from location /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base.\n",
      "2024-11-06 20:27:08,246 - modelscope - INFO - initialize model from /home/jiangpeiwen2/.cache/modelscope/hub/damo/nlp_rom_passage-ranking_chinese-base\n",
      "2024-11-06 20:27:09,377 - modelscope - INFO - head has no _keys_to_ignore_on_load_missing\n",
      "2024-11-06 20:27:09,520 - modelscope - INFO - All model checkpoint weights were used when initializing BertForTextRanking.\n",
      "\n",
      "2024-11-06 20:27:09,520 - modelscope - INFO - All the weights of BertForTextRanking were initialized from the model checkpoint If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTextRanking for predictions without further training.\n",
      "正在处理第0个文档的属性: 100%|██████████| 19/19 [02:59<00:00,  9.43s/it]\n"
     ]
    }
   ],
   "source": [
    "new_prompt_lists = []\n",
    "new_label_lists = []\n",
    "first_column_lists = []\n",
    "contexts_lists = []\n",
    "# for i in range(len(label_lists)):\n",
    "i = 0\n",
    "ret_list, new_label, first_column, contexts = get_prompts_labels( entity_lists[i], i, Plaintiff_claim_attributes, \n",
    "                                                                label_lists[i], core_ruled_text, _entity_type=None )\n",
    "                                                                #, contexts_ready=context_lists[i])\n",
    "new_prompt_lists.append( ret_list )\n",
    "new_label_lists.append( new_label )\n",
    "first_column_lists.append( first_column )\n",
    "contexts_lists.append( contexts )\n",
    "\n",
    "def compare_prompt( first_column_lists, new_label_lists ):\n",
    "    prompt_count = 0\n",
    "    label_count = 0\n",
    "    same_count = 0\n",
    "    role_dict = {}\n",
    "    not_label = []\n",
    "    for i in range( len(first_column_lists)):\n",
    "        prompt_count += len( first_column_lists[i] )\n",
    "        label_count += len( new_label_lists[i] )\n",
    "        # 遍历标签\n",
    "        for item in new_label_lists[i]:\n",
    "            role = item[0]\n",
    "            attr = item[1]\n",
    "            if role not in role_dict:\n",
    "                role_dict[role] = set()\n",
    "            role_dict[role].add( attr )\n",
    "        # 遍历提示词\n",
    "        for item in first_column_lists[i]:\n",
    "            role = item[0]\n",
    "            attr = item[1]\n",
    "            if role in role_dict and attr in role_dict[role]:\n",
    "                same_count +=1                                  # 提示词中和标签一致的结构\n",
    "            else:\n",
    "                not_label.append( item )\n",
    "    print(f\"label有{label_count}个，提示词有{prompt_count}个，一样的有{same_count}个\")\n",
    "    return not_label\n",
    "\n",
    "\n",
    "# not_label  = compare_prompt( first_column_lists, new_label_lists )      # label有2309个，提示词有3153个，一样的有2084个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款金额50万元整', '本院认为，原告贾瑞起与被告李安新之间最初签订《合作经营协议书》，原告所付款项50万元虽名为投资款，但根据该协议书约定，原告有权收回所付款项，并确保获得相对明确的收益，且不参与公司的任何管理，不承担任何亏损，双方的行为和资金往来更符合借贷的特征', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['虽然双方之间的联营合同纠纷并非本案的审理范围，但被告愿意配合法院查明事实，即使原告诉请256,000元之款项为合同履行过程中所欠款项，也并非真实存在，实际上原告还欠被告李安新联营款项，被告李安新会保留诉权']\\n问题：借款人（被告） (李安新) 辩称 需返回本金总额（元）？\\n注意：需返回本金总额指的是被告一共需要归还给原告的金额，单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['虽然双方之间的联营合同纠纷并非本案的审理范围，但被告愿意配合法院查明事实，即使原告诉请256,000元之款项为合同履行过程中所欠款项，也并非真实存在，实际上原告还欠被告李安新联营款项，被告李安新会保留诉权']\\n问题：借款人（被告） (李安新) 辩称 需返回利息总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回利息计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回利息计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 需返还利息率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['其中244,000元被告在到期日之前用其他费用进行了冲抵，双方确认欠款256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['虽然双方之间的联营合同纠纷并非本案的审理范围，但被告愿意配合法院查明事实，即使原告诉请256,000元之款项为合同履行过程中所欠款项，也并非真实存在，实际上原告还欠被告李安新联营款项，被告李安新会保留诉权']\\n问题：借款人（被告） (李安新) 辩称 需返回违约金总额（元）？\\n注意：单位为元，例如若为50万元，需要转换为500000元的形式。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2013年5月31日，原告向被告李安新付款50万元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金计算起始日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2013年5月31日，原告向被告李安新付款50万元']\\n问题：法院 (上海市闵行区人民法院) 判定 需返回违约金计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 需返回违约金计算截止日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和本金、利息混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 需返还违约金数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。不要和利息率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款金额50万元整', '被告李安新、汪少敏于本判决生效之日起十日内归还原告贾瑞起借款256,000元', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['虽然双方之间的联营合同纠纷并非本案的审理范围，但被告愿意配合法院查明事实，即使原告诉请256,000元之款项为合同履行过程中所欠款项，也并非真实存在，实际上原告还欠被告李安新联营款项，被告李安新会保留诉权']\\n问题：借款人（被告） (李安新) 辩称 初始约定的借款金额（元）？\\n注意：重点是首次约定的借款，不要和实际交付的金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['2013年5月31日，原告向被告李安新付款50万元', '2016年4月13日，经结算，被告李安新出具声明一份，内容为：“因欠贾瑞起人民币贰拾伍万陆仟元整（￥256,000.00），本人自愿将宝马3xxxl白色车辆抵押给贾瑞起，本人在30天内将欠贾瑞起￥256,000.00元还清，贾瑞起将车辆归还给我，如30天未归还，车辆由贾瑞起处置，车架号：LXXXXXXXXXXXXXXX6', '2015年12月3日，原告作为出借人与作为借款人的被告李安新签订了《借款协议》一份，约定：为了明确责任，恪守信用，在双方自愿、协商情况下特签订本合同以资共同信守', '借款期限自2015年12月3日起至2016年5月31日止']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的还款日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和实际归还的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 初始约定的还款日期？\\n注意：请重点关注上下文中具备年-月-日格式的部分。不要和实际归还的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的利率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的逾期利率数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。很少见，不要和正常利率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['合同期满5年后，甲方继续经营，利润按照以上利润支付给乙方，如甲方不再经营此区域韵达，甲方将此区域韵达经营权转让给第三方，转让总金额甲方支付给乙方15%区域增值金额']\\n问题：法院 (上海市闵行区人民法院) 判定 初始约定的违约金数值（百分比或元）？\\n注意：请重点关注上下文中有%符号后缀的数值。很少见，不要和利率混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['特别是，被告李安新嗣后与原告签订《借款协议》并出具借据，将原告所付50万元款项进一步明确为借款，故双方形成的是借贷关系', '关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '借款金额50万元整', '乙方两年内发出的所有快件（不限量）按照总公司内部价格结算，甲方给乙方韵达结算账号和密码，甲方不加任何费用，乙方自购面单价格每张2.10元，乙方所发出每票快件甲方收取0.70元']\\n问题：法院 (上海市闵行区人民法院) 判定 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款', '事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['虽然双方之间的联营合同纠纷并非本案的审理范围，但被告愿意配合法院查明事实，即使原告诉请256,000元之款项为合同履行过程中所欠款项，也并非真实存在，实际上原告还欠被告李安新联营款项，被告李安新会保留诉权']\\n问题：借款人（被告） (李安新) 辩称 借款实际交付金额（元）？\\n注意：是实际上原告给被告的金额，不要和约定的借款金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['同日，被告李安新出具了借据，载明：今借到贾瑞起50万元整（本金），借款期限自2015年12月3日起至2016年5月31日止，注：此款于2013年5月31日收到', '2015年12月3日，原告作为出借人与作为借款人的被告李安新签订了《借款协议》一份，约定：为了明确责任，恪守信用，在双方自愿、协商情况下特签订本合同以资共同信守', '借款期限自2015年12月3日起至2016年5月31日止']\\n问题：法院 (上海市闵行区人民法院) 判定 借款实际交付时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是实际上原告把钱给被告的日期，不要和其他的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 借款实际交付时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是实际上原告把钱给被告的日期，不要和其他的日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['借款期限自2015年12月3日起至2016年5月31日止', '2016年4月13日，经结算，被告李安新出具声明一份，内容为：“因欠贾瑞起人民币贰拾伍万陆仟元整（￥256,000.00），本人自愿将宝马3xxxl白色车辆抵押给贾瑞起，本人在30天内将欠贾瑞起￥256,000.00元还清，贾瑞起将车辆归还给我，如30天未归还，车辆由贾瑞起处置，车架号：LXXXXXXXXXXXXXXX6']\\n问题：法院 (上海市闵行区人民法院) 判定 已还款时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是被告还钱给原告的日期，不要和其他日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['事实和理由：被告因公司资金周转紧张，于2013年5月31日向原告借款50万元，当时双方未签订书面借款协议，也没有就借款偿还时间进行约定', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 已还款时间？\\n注意：请重点关注上下文中具备年-月-日格式的部分。是被告还钱给原告的日期，不要和其他日期混淆。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['关于欠款金额，被告李安新在与原告结算后出具声明，确认尚欠原告256,000元，结合双方的陈述，该数额系借款50万元扣除了有关费用后的余额，而被告李安新在收到50万元后并未向原告还款，其出具声明后也未向原告还款，故原告主张还款金额为256,000元，依据充分，本院予以支持', '第一年甲方归还乙方10万元，第二年甲方归还乙方20万元，第三年甲方归还乙方2万元，第三、四、五年甲方按规定每年支付给乙方15万元']\\n问题：法院 (上海市闵行区人民法院) 判定 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['原告贾瑞起向本院提出诉讼请求：判令两被告归还原告借款本金256,000元', '2015年底，原告要求被告偿还前述借款，被告表示暂无偿还能力，经双方协商，原、被告于2015年12月3日补签了借款协议，将借款时间重新约定为2015年12月3日至2016年5月31日，同时被告出具了借据，明确表示已于2013年5月31日收到前述50万元借款']\\n问题：出借人（原告） (贾瑞起) 诉称 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\",\n",
       " \"\\n你是一名信息抽取专家，请你从法院判决文书上下文中抽取问题中要求的日期、金额或利率。请注意区分法院、原告、被告三者对同一事实的不同主张，不要张冠李戴。\\n（1）首先，你需要判断上下文中的信息是否包含问题要求的特定对象对某个案件事实的陈述，如果没有（很有可能是无效的上下文），请大胆回答<NOT FOUND>。\\n（2）其次，你要判断该数值是否是问题中 主体角色 的主张。例如，上下文中若只有原告主张归还500元，而问题是被告主张归还多少元时，不应该回答500。\\n\\n相关上下文：['虽然双方之间的联营合同纠纷并非本案的审理范围，但被告愿意配合法院查明事实，即使原告诉请256,000元之款项为合同履行过程中所欠款项，也并非真实存在，实际上原告还欠被告李安新联营款项，被告李安新会保留诉权']\\n问题：借款人（被告） (李安新) 辩称 已还款金额（元）？\\n注意：是被告第一次实际还给原告的金额，不要和其他金额混淆。单位为元，例如若为50万元，需要转换为500000元的形式。\\n答案：\\n\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "new_prompt_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data( new_prompt_lists, \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_prompt_list.pickle\")\n",
    "save_data( new_label_lists, \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_label_list.pickle\")\n",
    "save_data( first_column_lists, \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_column_list.pickle\")\n",
    "save_data( contexts_lists, \"/home/jiangpeiwen2/jiangpeiwen2/TKGT/Hybird_RAG/temp/cpl/cpl_data_try_cell_all_context_list.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将label list分成不同字段的list并统计\n",
    "def split_label( label_lists ):\n",
    "    split_dict = {\n",
    "        \"list\": {},\n",
    "        \"count\":{}\n",
    "    }\n",
    "    for key in Plaintiff_claim_attributes.keys():\n",
    "        split_dict[\"list\"][key] = OrderedDict()\n",
    "        split_dict[\"count\"][key] = 0\n",
    "    for i in range( len(label_lists) ):\n",
    "        # 构建本档案的所有三元组情况\n",
    "        temp_dict = {}\n",
    "        for item in label_lists[i]:\n",
    "            if item[1] not in temp_dict:\n",
    "                temp_dict[item[1]] = set()\n",
    "            temp_dict[item[1]].add( item )\n",
    "        # 将本档案加入全局split_dict\n",
    "        for key in split_dict[\"list\"].keys():\n",
    "            if key in temp_dict:\n",
    "                split_dict[\"list\"][key][i] = temp_dict[key]\n",
    "                split_dict[\"count\"][key] += 1\n",
    "            else:\n",
    "                split_dict[\"list\"][key][i] = []\n",
    "    return split_dict\n",
    "split_dict_label = split_label( label_lists )\n",
    "split_dict_predict = split_label( predict_lists )\n",
    "# 显示哪个文件\n",
    "# texts[4].split(\"docx###\")[0]\n",
    "start_interest_label = split_dict_label[\"list\"][\"需返回利息计算起始日期\"]               # 199-135   label-predict\n",
    "end_interest_label = split_dict_label[\"list\"][\"需返回利息计算截止日期\"]                 # 33-26\n",
    "start_over_interest_label = split_dict_label[\"list\"][\"需返回逾期利息计算起始日期\"]       # 48-59\n",
    "end_over_interest_label = split_dict_label[\"list\"][\"需返回逾期利息计算截止日期\"]         # 5-2\n",
    "start_default_interest_label = split_dict_label[\"list\"][\"需返回违约金计算起始日期\"]      # 5-9\n",
    "end_default_interest_label = split_dict_label[\"list\"][\"需返回违约金计算截止日期\"]        # 0-1\n",
    "\n",
    "agreed_pay_label = split_dict_label[\"list\"][\"初始约定的还款日期\"]                       # 92-101\n",
    "actual_give_label = split_dict_label[\"list\"][\"借款实际交付时间1\"]                       # 102-163\n",
    "actual_pay_label = split_dict_label[\"list\"][\"已还款时间1\"]                              # 19-11\n",
    "\n",
    "def get_pairs( part, split_dict_label, split_dict_predict):\n",
    "    label_part, predict_part = [], []\n",
    "    for i in range(len( split_dict_label[\"list\"][part]) ):\n",
    "        label_part.append( split_dict_label[\"list\"][part][i] )\n",
    "        predict_part.append( split_dict_predict[\"list\"][part][i] )\n",
    "    return label_part, predict_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "predict_list = predict_lists[index]\n",
    "#prompt_list = prompt_lists[index]\n",
    "_label = label_lists[index]\n",
    "\n",
    "# entity_list = ['法院 (上海市闵行区人民法院)', '出借人（原告） (贾瑞起)', '借款人（被告） (李安新)', '借款人（被告） (汪少敏)']\n",
    "# prompt_list, new_label, first_column, contexts = get_prompts_labels( entity_list, Plaintiff_claim_attributes, _label)\n",
    "# 推理\n",
    "# predicts = online_local_chat( prompt_list )\n",
    "# 将原始的label和Predict集合准备成字典以备显示使用\n",
    "roles = {}\n",
    "for i, sets in enumerate( [_label, predict_list] ):\n",
    "    for item in sets:\n",
    "        if item[0] not in roles:\n",
    "            roles[ item[0] ] = [ set(), set()]  # 标签、预测\n",
    "        roles[ item[0] ][i].add( item )\n",
    "roles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare( roles[role][0],  roles[role][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
